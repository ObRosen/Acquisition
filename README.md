# 代码使用

## 棋局数据获取、读取与处理

- 从[La base WTHOR | Fédération Française d'Othello (ffothello.org)](https://www.ffothello.org/informatique/la-base-wthor/)中可获取1979-2023年黑白棋锦标赛的.wtb格式数据文件，创建`gamedata`文件夹，将数据文件存入该文件夹。
- `read_wth.py`中定义了读取.wtb格式数据文件的函数`read_wthor_files()`，以路径为自变量，输出训练集和测试集。
- `load_data.py`中定义了整个程序中所需的各种数据格式处理的函数。有些最终没有用到，可以忽略。
	- `dedup()`用于数据集旋转对称去重。
	- `load_tensor()`与`load_dataframe()`将两种相应格式的数据集分batch，用于后续使用。

## 神经网络输出数据的获取

- `load_net.py`定义了`loadNetOutput()`函数，顾名思义，从models文件夹中的checkpoint文件中读取神经网络的结构，并输入此前生成的棋局数据集，获取相应每一层残差块的输出。

## 人类概念的封装

- `concept.py`中定义了各种策略的函数，参考了[OrangeX4](https://orangex4.cool/post/reversi/)的代码，在此基础上延伸了一些。

## 探针训练、测试评估

- `linear_probe.py`为本项目的主文件，在models文件夹和gamedata文件夹准备好的情况下，更改好需要的`file_list, epoch_list, concept_list`后直接运行此文件即可。
	- 本文件关于正确率试用了两种定义，源头是`r2_score()`和`r2_score_0()`，由此产生结果对`accuracy`与`accuracy_0`等，如不需要可以删去。
- 注意此文件中使用的`print()`函数在`rewrite_print.py`中重载过，使输出结果同时打印在屏幕和`log_file`文件夹中的日志文件里。

### linear_probe.py

定义了`LinearModel`类，由一个`Linear`层组成。一个损失函数`loss_f1`，由平方误差和一个$L_1$正则项(**稀疏探针要用L1正则**)组成。

- **`train()`函数**：输入模型、训练数据集、训练标签集、$\lambda$值、学习率、epoch值，`train()`函数完成了一个根据损失函数更新模型参数的过程。

- **`decide_lambda_lr()`函数**：输入模型、自变量、因变量、交叉验证折数，`decide_lambda()`函数将数据分为k折，依次取其中一个作为验证集，剩下的作为训练集，在训练集上对不同的$\lambda$取值和学习率取值进行遍历训练，然后在验证集上计算平均损失水平，选定平均损失水平最低的$\lambda$和学习率为最优$\lambda$与最优学习率，由此确定了最佳正则化系数和最佳学习率。

- **`concept_probe()`函数**：输入概念的名字、自变量训练集、神经网络输入训练集，`concept_probe()`函数首先生成一个与概念对应的因变量训练集$c(z^0)$，然后在自变量训练集上用上述方法训练出对于当前概念的最佳探针$g$，并返回这个线性模型。

- **`test_accuracy()`函数**：输入概念的名字、模型、自变量测试集、神经网络输入测试集，首先生成一个与概念对应的因变量测试集$c(z^0)$，然后在自变量测试集上测试模型的正确率(即$R^2$值)，并返回这个正确率。

- **`compute_results()`函数**：组合上述函数进行完整的计算。

## 三维曲面图绘制

- `draw_plot.py`从`log_file`中的正确率日志文件读取数据并画图。
- 内存方面的问题。

## 一些没做的补丁

- 许多参数写进config.ini通过reversi_config.py读取会更好，由于时间限制目前没有作这个处理。
- ……

# 实验原理

### 论文

**人类编码概念** 我们采取一种简单的概念定义方式：用户定义的从网络输入$z^0$到Fig.1 中橙色实线的函数。一个简单的示例概念就可以检测出当前棋手方是否有一对双象：$$c(z^0)=\left\{\begin{matrix}1&\mathbf{z^0\quad has\quad a\quad bishop\quad pair}\\0&\mathbf{otherwise}\end{matrix}\right.$$
大多数概念比这要复杂，可能会取一系列整数值（例如：卒的个数）或连续值（例如：由Stockfish 8国际象棋引擎测量的总分）。一个更复杂的概念的例子是行动力(mobility)，国际象棋引擎的设计者可以设计一个函数来对$z^0$中当前棋手方的的棋子行动力相比对手有多大行动力给出分数。考虑我们的目的，概念是预先设定的函数，封装了特定的领域专业知识。
我们使用Stockfish 8中的局面评估函数组件作为概念，连同我们自己实现的116个概念。

**概念与激活数据集** 我们从完整ChessBase仓库中随机选取$10^5$局游戏，计算该数据集中每一个局面(原文position)的概念值以及AlphaZero激活值，然后从去重后的数据中随机采样中训练、验证、测试集。连续值概念使用$10^5$个不重复的局面(而非游戏)组成的训练集，以及另外$3\times 10^4$个不重复的局面组成的验证机和测试集。二分值概念平衡采样，使其正例和负例个数相同，这种采样原则使得可供训练的数据受到限制，鉴于有些概念很少出现。二分值概念的最小训练集大小为50363，最大为$10^5$。

**探查人类概念** 我们通过一个简单的线性探查方法大规模地搜索人类概念；对于给定的概念$c$，我们从深度为$d$的神经网络激活中训练一个稀疏回归探针$g$，用以预测$c$的值。训练集由$10^5$个从ChessBase数据集中自然出现的棋盘局面组成，见Fig 1. 我们报告的分值(测试正确率)在一个独立的测试集中测量。通过比较不同的概念探针(既对AlphaZero自我对战循环中的不同训练步数比较，也对每一个网络中的不同层级比较)，我们可以提取出何时何地目标概念被网络习得。令$z^d=f^{1:d}(z^0)$表示第$d$层的残差块激活$z^d$为$z^0$的一个函数，更正式地，给定$f^{1:d}(z^0)$与一个概念$c(z^0)$，我们训练一个探针$g_w(z^d)$来使一个损失函数$L$最小化：$$w^*={{argmin}\atop {w}}L(g_w(f^{1:d}(z^0)),c(z^0))+\lambda|w|$$其中标量$\lambda\geq 0$为一个由交叉验证决定的$L_1$正则化参数，损失函数为平方误差损失：$$L(x,y)=(x-y)^2$$连续概念的探针采用线性回归$$g_w(z^d)=w^T[z^d,1]$$二分值概念的探针采用逻辑回归$$g_w(z^d)=\sigma(w^T[z^d,1])$$

*Fig 1:在一个测试集上平均后的逼近的质量($g(z^d)\approx c(z^0)$)即表明了一个神经网络层线性编码该人类概念的表现如何。对于一个给定的概念，此过程在每个神经网络的所有层级的(探针)训练过程中产生的一系列网络中重复。For a given concept, the process is repeated for the sequence of networks that are produced during training for all the layers in each network*

在评估中，我们用正确类预测分数(the fraction of correct class prediction)来为二分值探针打分（经过标准化，使得50%正确率被设定为0分），其他探针用确定性系数$r^2$打分。


### 梳理思路

怎么做：
1. 数据集的获取：
	1. $z^0$：棋盘局面数据，相当于$s$，即神经网络的输入。局面值数据将被分为训练集、验证集与测试集。
	2. 每一个$z^0$在每一代(training steps)训练出的ResNet网络中的每一层(block)的输出$z^d_t, \forall d\in[1,15]$。对应的也分为训练集、验证集与测试集。
2. 函数的确定：
	1. 人类概念的抽象描述$c$，一个$c$负责一个概念。分为连续值和二分值两种。
		1. 人类概念：也许可以从黑白棋相关文献中找到对黑白棋的局面评估与常用策略，这些都是前代的方法中输入的人类经验。
		2. 人类概念的抽象描述：目前还不知道怎么获得，可能需要自己构造。
	2. 对于训练数据集，在每一代(training steps)训练出的ResNet网络中的每一层(block)的输出的线性或逻辑回归探针$g$，通过上式训练得出(使函数值$g(z^d)$与$c(z^0)$之间的平方误差$(g(z^d)-c(z^0))^2$与正则化项$\lambda|w|$最小)。
3. 计算：
	1. 测试正确率：在测试集上，将上面训练出的探针$g$代入$z^d$值，求**该值判断$c(z^0)$正确率**(正确类预测分数、确定性系数)的平均值(对整个测试集求平均)，得到该步骤、该层级的测试正确率。
	2. 画what-when-where图：对给定概念$c$，以block, training step, test accuracy为轴将上述值作三维图。从图中即可分析神经网络何时(training step)何处(block)习得了何种(what)人类概念。